
<!DOCTYPE html>


<html lang="en" data-content_root="" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>gpflux.layers &#8212; GPflux 0.1.0 documentation</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../../_static/styles/theme.css?digest=5b4479735964841361fd" rel="stylesheet" />
<link href="../../../_static/styles/bootstrap.css?digest=5b4479735964841361fd" rel="stylesheet" />
<link href="../../../_static/styles/pydata-sphinx-theme.css?digest=5b4479735964841361fd" rel="stylesheet" />

  
  <link href="../../../_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=5b4479735964841361fd" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../../../_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../../_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../../_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../../../_static/pygments.css?v=a746c00c" />
    <link rel="stylesheet" type="text/css" href="../../../_static/graphviz.css?v=eafc0fe6" />
    <link rel="stylesheet" type="text/css" href="../../../_static/pydata-custom.css?v=c27e38e3" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../../_static/scripts/bootstrap.js?digest=5b4479735964841361fd" />
<link rel="preload" as="script" href="../../../_static/scripts/pydata-sphinx-theme.js?digest=5b4479735964841361fd" />
  <script src="../../../_static/vendor/fontawesome/6.1.2/js/all.min.js?digest=5b4479735964841361fd"></script>

    <script data-url_root="../../../" id="documentation_options" src="../../../_static/documentation_options.js?v=2389946f"></script>
    <script src="../../../_static/doctools.js?v=888ff710"></script>
    <script src="../../../_static/sphinx_highlight.js?v=4825356b"></script>
    <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script>window.MathJax = {"tex": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true}, "options": {"ignoreHtmlClass": "tex2jax_ignore|mathjax_ignore|document", "processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'autoapi/gpflux/layers/index';</script>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" />
    <link rel="next" title="gpflux.layers.basis_functions" href="basis_functions/index.html" />
    <link rel="prev" title="gpflux.experiment_support.tensorboard" href="../experiment_support/tensorboard/index.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a class="skip-link" href="#main-content">Skip to main content</a>
  
  <div id="pst-scroll-pixel-helper"></div>

  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>
    Back to top
  </button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search the docs ..."
         aria-label="Search the docs ..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <nav class="bd-header navbar navbar-expand-lg bd-navbar">
<div class="bd-header__inner bd-page-width">
  <label class="sidebar-toggle primary-toggle" for="__primary">
    <span class="fa-solid fa-bars"></span>
  </label>
  
  
  <div class="col-lg-3 navbar-header-items__start">
    
      <div class="navbar-item">

  

<a class="navbar-brand logo" href="../../../index.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../../../_static/logo.png" class="logo__image only-light" alt="GPflux 0.1.0 documentation - Home"/>
    <script>document.write(`<img src="../../../_static/logo.png" class="logo__image only-dark" alt="GPflux 0.1.0 documentation - Home"/>`);</script>
  
  
</a></div>
    
  </div>
  
  <div class="col-lg-9 navbar-header-items">
    
    <div class="me-auto navbar-header-items__center">
      
        <div class="navbar-item">
<nav class="navbar-nav">
  <p class="sidebar-header-items__title"
     role="heading"
     aria-level="1"
     aria-label="Site Navigation">
    Site Navigation
  </p>
  <ul class="bd-navbar-elements navbar-nav">
    
                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../../index.html">
                        GPflux
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../../notebooks/benchmarks.html">
                        Benchmarks
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../../tutorials.html">
                        Tutorials
                      </a>
                    </li>
                

                    <li class="nav-item current active">
                      <a class="nav-link nav-internal" href="../index.html">
                        API Reference
                      </a>
                    </li>
                
  </ul>
</nav></div>
      
    </div>
    
    
    <div class="navbar-header-items__end">
      
        <div class="navbar-item navbar-persistent--container">
          

 <script>
 document.write(`
   <button class="btn navbar-btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script>
        </div>
      
      
        <div class="navbar-item">

<script>
document.write(`
  <button class="btn btn-sm navbar-btn theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch nav-link" data-mode="light"><i class="fa-solid fa-sun fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="dark"><i class="fa-solid fa-moon fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="auto"><i class="fa-solid fa-circle-half-stroke fa-lg"></i></span>
  </button>
`);
</script></div>
      
        <div class="navbar-item"><ul class="navbar-icon-links navbar-nav"
    aria-label="Icon Links">
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://github.com/secondmind-labs/gpflux" title="GitHub" class="nav-link" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><span><i class="fa-brands fa-square-github fa-lg" aria-hidden="true"></i></span>
            <span class="sr-only">GitHub</span></a>
        </li>
</ul></div>
      
    </div>
    
  </div>
  
  
    <div class="navbar-persistent--mobile">

 <script>
 document.write(`
   <button class="btn navbar-btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script>
    </div>
  

  
    <label class="sidebar-toggle secondary-toggle" for="__secondary" tabindex="0">
      <span class="fa-solid fa-outdent"></span>
    </label>
  
</div>

    </nav>
  
  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
      <div class="sidebar-header-items__center">
        
          <div class="navbar-item">
<nav class="navbar-nav">
  <p class="sidebar-header-items__title"
     role="heading"
     aria-level="1"
     aria-label="Site Navigation">
    Site Navigation
  </p>
  <ul class="bd-navbar-elements navbar-nav">
    
                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../../index.html">
                        GPflux
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../../notebooks/benchmarks.html">
                        Benchmarks
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../../tutorials.html">
                        Tutorials
                      </a>
                    </li>
                

                    <li class="nav-item current active">
                      <a class="nav-link nav-internal" href="../index.html">
                        API Reference
                      </a>
                    </li>
                
  </ul>
</nav></div>
        
      </div>
    
    
    
      <div class="sidebar-header-items__end">
        
          <div class="navbar-item">

<script>
document.write(`
  <button class="btn btn-sm navbar-btn theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch nav-link" data-mode="light"><i class="fa-solid fa-sun fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="dark"><i class="fa-solid fa-moon fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="auto"><i class="fa-solid fa-circle-half-stroke fa-lg"></i></span>
  </button>
`);
</script></div>
        
          <div class="navbar-item"><ul class="navbar-icon-links navbar-nav"
    aria-label="Icon Links">
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://github.com/secondmind-labs/gpflux" title="GitHub" class="nav-link" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><span><i class="fa-brands fa-square-github fa-lg" aria-hidden="true"></i></span>
            <span class="sr-only">GitHub</span></a>
        </li>
</ul></div>
        
      </div>
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">
<nav class="bd-docs-nav bd-links"
     aria-label="Section Navigation">
  <p class="bd-links__title" role="heading" aria-level="1">Section Navigation</p>
  <div class="bd-toc-item navbar-nav"><ul class="current nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../architectures/index.html">gpflux.architectures</a><input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-1"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../architectures/constant_input_dim_deep_gp/index.html">gpflux.architectures.constant_input_dim_deep_gp</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../encoders/index.html">gpflux.encoders</a><input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-2"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../encoders/directly_parameterized_encoder/index.html">gpflux.encoders.directly_parameterized_encoder</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../experiment_support/index.html">gpflux.experiment_support</a><input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-3"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../experiment_support/ci_utils/index.html">gpflux.experiment_support.ci_utils</a></li>
<li class="toctree-l2"><a class="reference internal" href="../experiment_support/tensorboard/index.html">gpflux.experiment_support.tensorboard</a></li>
</ul>
</li>
<li class="toctree-l1 current active has-children"><a class="current reference internal" href="#">gpflux.layers</a><input checked="" class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-4"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2 has-children"><a class="reference internal" href="basis_functions/index.html">gpflux.layers.basis_functions</a><input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-5"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3 has-children"><a class="reference internal" href="basis_functions/fourier_features/index.html">gpflux.layers.basis_functions.fourier_features</a><input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-6"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="basis_functions/fourier_features/quadrature/index.html">gpflux.layers.basis_functions.fourier_features.quadrature</a></li>
<li class="toctree-l4"><a class="reference internal" href="basis_functions/fourier_features/random/index.html">gpflux.layers.basis_functions.fourier_features.random</a></li>
<li class="toctree-l4"><a class="reference internal" href="basis_functions/fourier_features/base/index.html">gpflux.layers.basis_functions.fourier_features.base</a></li>
<li class="toctree-l4"><a class="reference internal" href="basis_functions/fourier_features/utils/index.html">gpflux.layers.basis_functions.fourier_features.utils</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="bayesian_dense_layer/index.html">gpflux.layers.bayesian_dense_layer</a></li>
<li class="toctree-l2"><a class="reference internal" href="gp_layer/index.html">gpflux.layers.gp_layer</a></li>
<li class="toctree-l2"><a class="reference internal" href="latent_variable_layer/index.html">gpflux.layers.latent_variable_layer</a></li>
<li class="toctree-l2"><a class="reference internal" href="likelihood_layer/index.html">gpflux.layers.likelihood_layer</a></li>
<li class="toctree-l2"><a class="reference internal" href="trackable_layer/index.html">gpflux.layers.trackable_layer</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../models/index.html">gpflux.models</a><input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-7"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../models/deep_gp/index.html">gpflux.models.deep_gp</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../optimization/index.html">gpflux.optimization</a><input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-8"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../optimization/keras_natgrad/index.html">gpflux.optimization.keras_natgrad</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../sampling/index.html">gpflux.sampling</a><input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-9"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../sampling/kernel_with_feature_decomposition/index.html">gpflux.sampling.kernel_with_feature_decomposition</a></li>
<li class="toctree-l2"><a class="reference internal" href="../sampling/sample/index.html">gpflux.sampling.sample</a></li>
<li class="toctree-l2"><a class="reference internal" href="../sampling/utils/index.html">gpflux.sampling.utils</a></li>
</ul>
</li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../callbacks/index.html">gpflux.callbacks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../exceptions/index.html">gpflux.exceptions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../helpers/index.html">gpflux.helpers</a></li>
<li class="toctree-l1"><a class="reference internal" href="../losses/index.html">gpflux.losses</a></li>
<li class="toctree-l1"><a class="reference internal" href="../math/index.html">gpflux.math</a></li>
<li class="toctree-l1"><a class="reference internal" href="../runtime_checks/index.html">gpflux.runtime_checks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../types/index.html">gpflux.types</a></li>
<li class="toctree-l1"><a class="reference internal" href="../version/index.html">gpflux.version</a></li>
</ul>
</div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        
          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item">



<nav aria-label="Breadcrumb">
  <ul class="bd-breadcrumbs">
    
    <li class="breadcrumb-item breadcrumb-home">
      <a href="../../../index.html" class="nav-link" aria-label="Home">
        <i class="fa-solid fa-home"></i>
      </a>
    </li>
    
    <li class="breadcrumb-item"><a href="../index.html" class="nav-link">gpflux</a></li>
    
    <li class="breadcrumb-item active" aria-current="page">gpflux.layers</li>
  </ul>
</nav>
</div>
      
    </div>
  
  
</div>
</div>
              
              
              
                
<div id="searchbox"></div>
                <article class="bd-article" role="main">
                  
  <section id="module-gpflux.layers">
<span id="gpflux-layers"></span><h1>gpflux.layers<a class="headerlink" href="#module-gpflux.layers" title="Permalink to this heading">#</a></h1>
<p>Layers</p>
<section id="subpackages">
<h2>Subpackages<a class="headerlink" href="#subpackages" title="Permalink to this heading">#</a></h2>
<div class="toctree-wrapper compound">
<ul>
<li class="toctree-l1"><a class="reference internal" href="basis_functions/index.html">gpflux.layers.basis_functions</a></li>
</ul>
</div>
</section>
<section id="submodules">
<h2>Submodules<a class="headerlink" href="#submodules" title="Permalink to this heading">#</a></h2>
<div class="toctree-wrapper compound">
<ul>
<li class="toctree-l1"><a class="reference internal" href="bayesian_dense_layer/index.html">gpflux.layers.bayesian_dense_layer</a></li>
<li class="toctree-l1"><a class="reference internal" href="gp_layer/index.html">gpflux.layers.gp_layer</a></li>
<li class="toctree-l1"><a class="reference internal" href="latent_variable_layer/index.html">gpflux.layers.latent_variable_layer</a></li>
<li class="toctree-l1"><a class="reference internal" href="likelihood_layer/index.html">gpflux.layers.likelihood_layer</a></li>
<li class="toctree-l1"><a class="reference internal" href="trackable_layer/index.html">gpflux.layers.trackable_layer</a></li>
</ul>
</div>
</section>
<section id="package-contents">
<h2>Package Contents<a class="headerlink" href="#package-contents" title="Permalink to this heading">#</a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="gpflux.layers.BayesianDenseLayer">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">BayesianDenseLayer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_dim</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.12)"><span class="pre">int</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_dim</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.12)"><span class="pre">int</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_data</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.12)"><span class="pre">int</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">w_mu</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v2.0)"><span class="pre">numpy.ndarray</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.12)"><span class="pre">None</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">w_sqrt</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v2.0)"><span class="pre">numpy.ndarray</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.12)"><span class="pre">None</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">activation</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Callable</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.12)"><span class="pre">None</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">is_mean_field</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.12)"><span class="pre">bool</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">temperature</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.12)"><span class="pre">float</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.0001</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/gpflux/layers/bayesian_dense_layer.html#BayesianDenseLayer"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#gpflux.layers.BayesianDenseLayer" title="Permalink to this definition">#</a></dt>
<dd><p>Bases: <a class="reference internal" href="trackable_layer/index.html#gpflux.layers.trackable_layer.TrackableLayer" title="gpflux.layers.trackable_layer.TrackableLayer"><code class="xref py py-obj docutils literal notranslate"><span class="pre">gpflux.layers.trackable_layer.TrackableLayer</span></code></a></p>
<p>A dense (fully-connected) layer for variational Bayesian neural networks.</p>
<p>This layer holds the mean and square-root of the variance of the
distribution over the weights. This layer also has a temperature for
cooling (or heating) the posterior.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input_dim</strong> – The input dimension (excluding bias) of this layer.</p></li>
<li><p><strong>output_dim</strong> – The output dimension of this layer.</p></li>
<li><p><strong>num_data</strong> – The number of points in the training dataset (used for
scaling the KL regulariser).</p></li>
<li><p><strong>w_mu</strong> – Initial value of the variational mean for weights + bias.
If not specified, this defaults to <a class="reference internal" href="../helpers/index.html#gpflux.helpers.xavier_initialization_numpy" title="gpflux.helpers.xavier_initialization_numpy"><code class="xref any py py-func docutils literal notranslate"><span class="pre">xavier_initialization_numpy</span></code></a>
for the weights and zero for the bias.</p></li>
<li><p><strong>w_sqrt</strong> – Initial value of the variational Cholesky of the
(co)variance for weights + bias. If not specified, this defaults to
1e-5 * Identity.</p></li>
<li><p><strong>activation</strong> – The activation function. If not specified, this defaults to the identity.</p></li>
<li><p><strong>is_mean_field</strong> – Determines whether the approximation to the
weight posterior is mean field. Must be consistent with the shape
of <code class="docutils literal notranslate"><span class="pre">w_sqrt</span></code>, if specified.</p></li>
<li><p><strong>temperature</strong> – The KL loss will be scaled by this factor.
Can be used for cooling (&lt; 1.0) or heating (&gt; 1.0) the posterior.
As suggested in <a class="reference external" href="http://proceedings.mlr.press/v119/wenzel20a">“How Good is the Bayes Posterior in Deep Neural
Networks Really?” by Wenzel et al. (2020)</a> the default value
is a cold <code class="docutils literal notranslate"><span class="pre">1e-4</span></code>.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="gpflux.layers.BayesianDenseLayer.build">
<span class="sig-name descname"><span class="pre">build</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_shape</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">gpflux.types.ShapeType</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.12)"><span class="pre">None</span></a></span></span><a class="reference internal" href="../../../_modules/gpflux/layers/bayesian_dense_layer.html#BayesianDenseLayer.build"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#gpflux.layers.BayesianDenseLayer.build" title="Permalink to this definition">#</a></dt>
<dd><p>Build the variables necessary on first call</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="gpflux.layers.BayesianDenseLayer.predict_samples">
<span class="sig-name descname"><span class="pre">predict_samples</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">gpflow.base.TensorType</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_samples</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.12)"><span class="pre">int</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.12)"><span class="pre">None</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference external" href="https://www.tensorflow.org/api_docs/python/tf/Tensor" title="(in TensorFlow v2.4)"><span class="pre">tf.Tensor</span></a></span></span><a class="reference internal" href="../../../_modules/gpflux/layers/bayesian_dense_layer.html#BayesianDenseLayer.predict_samples"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#gpflux.layers.BayesianDenseLayer.predict_samples" title="Permalink to this definition">#</a></dt>
<dd><p>Samples from the approximate posterior at N test inputs, with input_dim = D, output_dim = Q.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>inputs</strong> – The inputs to predict at; shape <code class="docutils literal notranslate"><span class="pre">[N,</span> <span class="pre">D]</span></code>.</p></li>
<li><p><strong>num_samples</strong> – The number of samples S, to draw.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Samples, shape <code class="docutils literal notranslate"><span class="pre">[S,</span> <span class="pre">N,</span> <span class="pre">Q]</span></code> if S is not None else <code class="docutils literal notranslate"><span class="pre">[N,</span> <span class="pre">Q]</span></code>.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="gpflux.layers.BayesianDenseLayer.call">
<span class="sig-name descname"><span class="pre">call</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">gpflow.base.TensorType</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">training</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.12)"><span class="pre">bool</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.12)"><span class="pre">None</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference external" href="https://www.tensorflow.org/api_docs/python/tf/Tensor" title="(in TensorFlow v2.4)"><span class="pre">tf.Tensor</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">gpflow.models.model.MeanAndVariance</span></span></span><a class="reference internal" href="../../../_modules/gpflux/layers/bayesian_dense_layer.html#BayesianDenseLayer.call"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#gpflux.layers.BayesianDenseLayer.call" title="Permalink to this definition">#</a></dt>
<dd><p>The default behaviour upon calling this layer.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="gpflux.layers.BayesianDenseLayer.prior_kl">
<span class="sig-name descname"><span class="pre">prior_kl</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference external" href="https://www.tensorflow.org/api_docs/python/tf/Tensor" title="(in TensorFlow v2.4)"><span class="pre">tf.Tensor</span></a></span></span><a class="reference internal" href="../../../_modules/gpflux/layers/bayesian_dense_layer.html#BayesianDenseLayer.prior_kl"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#gpflux.layers.BayesianDenseLayer.prior_kl" title="Permalink to this definition">#</a></dt>
<dd><p>Returns the KL divergence <code class="docutils literal notranslate"><span class="pre">KL[q(u)∥p(u)]</span></code> from the prior <code class="docutils literal notranslate"><span class="pre">p(u)</span> <span class="pre">=</span> <span class="pre">N(0,</span> <span class="pre">I)</span></code> to
the variational distribution <code class="docutils literal notranslate"><span class="pre">q(u)</span> <span class="pre">=</span> <span class="pre">N(w_mu,</span> <span class="pre">w_sqrt²)</span></code>.</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="gpflux.layers.GPLayer">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">GPLayer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">kernel</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">gpflow.kernels.MultioutputKernel</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">inducing_variable</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">gpflow.inducing_variables.MultioutputInducingVariables</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_data</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.12)"><span class="pre">int</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">mean_function</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">gpflow.mean_functions.MeanFunction</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.12)"><span class="pre">None</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_samples</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.12)"><span class="pre">int</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.12)"><span class="pre">None</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">full_cov</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.12)"><span class="pre">bool</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">full_output_cov</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.12)"><span class="pre">bool</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_latent_gps</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.12)"><span class="pre">int</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">whiten</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.12)"><span class="pre">bool</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">name</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.12)"><span class="pre">str</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.12)"><span class="pre">None</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.12)"><span class="pre">bool</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/gpflux/layers/gp_layer.html#GPLayer"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#gpflux.layers.GPLayer" title="Permalink to this definition">#</a></dt>
<dd><p>Bases: <a class="reference external" href="https://www.tensorflow.org/probability/api_docs/python/tfp/layers/DistributionLambda" title="(in TensorFlow Probability v0.12)"><code class="docutils literal notranslate"><span class="pre">tfp.layers.DistributionLambda</span></code></a></p>
<p>A sparse variational multioutput GP layer. This layer holds the kernel,
inducing variables and variational distribution, and mean function.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>kernel</strong> – The multioutput kernel for this layer.</p></li>
<li><p><strong>inducing_variable</strong> – The inducing features for this layer.</p></li>
<li><p><strong>num_data</strong> – The number of points in the training dataset (see <a class="reference internal" href="#gpflux.layers.GPLayer.num_data" title="gpflux.layers.GPLayer.num_data"><code class="xref py py-attr docutils literal notranslate"><span class="pre">num_data</span></code></a>).</p></li>
<li><p><strong>mean_function</strong> – <p>The mean function that will be applied to the
inputs. Default: <code class="xref py py-class docutils literal notranslate"><span class="pre">Identity</span></code>.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The Identity mean function requires the input and output
dimensionality of this layer to be the same. If you want to
change the dimensionality in a layer, you may want to provide a
<code class="xref py py-class docutils literal notranslate"><span class="pre">Linear</span></code> mean function instead.</p>
</div>
</p></li>
<li><p><strong>num_samples</strong> – The number of samples to draw when converting the
<a class="reference external" href="https://www.tensorflow.org/probability/api_docs/python/tfp/layers/DistributionLambda" title="(in TensorFlow Probability v0.12)"><code class="xref py py-class docutils literal notranslate"><span class="pre">DistributionLambda</span></code></a> into a <a class="reference external" href="https://www.tensorflow.org/api_docs/python/tf/Tensor" title="(in TensorFlow v2.4)"><code class="xref any docutils literal notranslate"><span class="pre">tf.Tensor</span></code></a>, see
<a class="reference internal" href="#gpflux.layers.GPLayer._convert_to_tensor_fn" title="gpflux.layers.GPLayer._convert_to_tensor_fn"><code class="xref py py-meth docutils literal notranslate"><span class="pre">_convert_to_tensor_fn()</span></code></a>. Will be stored in the
<a class="reference internal" href="#gpflux.layers.GPLayer.num_samples" title="gpflux.layers.GPLayer.num_samples"><code class="xref py py-attr docutils literal notranslate"><span class="pre">num_samples</span></code></a> attribute.  If <a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.12)"><code class="xref any docutils literal notranslate"><span class="pre">None</span></code></a> (the default), draw a
single sample without prefixing the sample shape (see
<a class="reference external" href="https://www.tensorflow.org/probability/api_docs/python/tfp/distributions/Distribution" title="(in TensorFlow Probability v0.12)"><code class="xref py py-class docutils literal notranslate"><span class="pre">tfp.distributions.Distribution</span></code></a>’s <a class="reference external" href="https://www.tensorflow.org/probability/api_docs/python/tfp/distributions/Distribution#sample">sample()</a>
method).</p></li>
<li><p><strong>full_cov</strong> – Sets default behaviour of calling this layer
(<a class="reference internal" href="#gpflux.layers.GPLayer.full_cov" title="gpflux.layers.GPLayer.full_cov"><code class="xref py py-attr docutils literal notranslate"><span class="pre">full_cov</span></code></a> attribute):
If <a class="reference external" href="https://docs.python.org/3/library/constants.html#False" title="(in Python v3.12)"><code class="xref any docutils literal notranslate"><span class="pre">False</span></code></a> (the default), only predict marginals (diagonal
of covariance) with respect to inputs.
If <a class="reference external" href="https://docs.python.org/3/library/constants.html#True" title="(in Python v3.12)"><code class="xref any docutils literal notranslate"><span class="pre">True</span></code></a>, predict full covariance over inputs.</p></li>
<li><p><strong>full_output_cov</strong> – Sets default behaviour of calling this layer
(<a class="reference internal" href="#gpflux.layers.GPLayer.full_output_cov" title="gpflux.layers.GPLayer.full_output_cov"><code class="xref py py-attr docutils literal notranslate"><span class="pre">full_output_cov</span></code></a> attribute):
If <a class="reference external" href="https://docs.python.org/3/library/constants.html#False" title="(in Python v3.12)"><code class="xref any docutils literal notranslate"><span class="pre">False</span></code></a> (the default), only predict marginals (diagonal
of covariance) with respect to outputs.
If <a class="reference external" href="https://docs.python.org/3/library/constants.html#True" title="(in Python v3.12)"><code class="xref any docutils literal notranslate"><span class="pre">True</span></code></a>, predict full covariance over outputs.</p></li>
<li><p><strong>num_latent_gps</strong> – The number of (latent) GPs in the layer
(which can be different from the number of outputs, e.g. with a
<code class="xref py py-class docutils literal notranslate"><span class="pre">LinearCoregionalization</span></code> kernel).
This is used to determine the size of the
variational parameters <a class="reference internal" href="#gpflux.layers.GPLayer.q_mu" title="gpflux.layers.GPLayer.q_mu"><code class="xref py py-attr docutils literal notranslate"><span class="pre">q_mu</span></code></a> and <a class="reference internal" href="#gpflux.layers.GPLayer.q_sqrt" title="gpflux.layers.GPLayer.q_sqrt"><code class="xref py py-attr docutils literal notranslate"><span class="pre">q_sqrt</span></code></a>.
If possible, it is inferred from the <em>kernel</em> and <em>inducing_variable</em>.</p></li>
<li><p><strong>whiten</strong> – If <a class="reference external" href="https://docs.python.org/3/library/constants.html#True" title="(in Python v3.12)"><code class="xref any docutils literal notranslate"><span class="pre">True</span></code></a> (the default), uses the whitened parameterisation
of the inducing variables; see <a class="reference internal" href="#gpflux.layers.GPLayer.whiten" title="gpflux.layers.GPLayer.whiten"><code class="xref py py-attr docutils literal notranslate"><span class="pre">whiten</span></code></a>.</p></li>
<li><p><strong>name</strong> – The name of this layer.</p></li>
<li><p><strong>verbose</strong> – The verbosity mode. Set this parameter to <a class="reference external" href="https://docs.python.org/3/library/constants.html#True" title="(in Python v3.12)"><code class="xref any docutils literal notranslate"><span class="pre">True</span></code></a>
to show debug information.</p></li>
</ul>
</dd>
</dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="gpflux.layers.GPLayer.num_data">
<span class="sig-name descname"><span class="pre">num_data</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.12)"><span class="pre">int</span></a></em><a class="headerlink" href="#gpflux.layers.GPLayer.num_data" title="Permalink to this definition">#</a></dt>
<dd><p>The number of points in the training dataset. This information is used to
obtain the correct scaling between the data-fit and the KL term in the
evidence lower bound (ELBO).</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="gpflux.layers.GPLayer.whiten">
<span class="sig-name descname"><span class="pre">whiten</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.12)"><span class="pre">bool</span></a></em><a class="headerlink" href="#gpflux.layers.GPLayer.whiten" title="Permalink to this definition">#</a></dt>
<dd><p>This parameter determines the parameterisation of the inducing variables.</p>
<p>If <a class="reference external" href="https://docs.python.org/3/library/constants.html#True" title="(in Python v3.12)"><code class="xref any docutils literal notranslate"><span class="pre">True</span></code></a>, this layer uses the whitened (or non-centred) representation, in
which (at the example of inducing point inducing variables) <code class="docutils literal notranslate"><span class="pre">u</span> <span class="pre">=</span> <span class="pre">f(Z)</span> <span class="pre">=</span>
<span class="pre">cholesky(Kuu)</span> <span class="pre">v</span></code>, and we parameterise an approximate posterior on <code class="docutils literal notranslate"><span class="pre">v</span></code> as
<code class="docutils literal notranslate"><span class="pre">q(v)</span> <span class="pre">=</span> <span class="pre">N(q_mu,</span> <span class="pre">q_sqrt</span> <span class="pre">q_sqrtᵀ)</span></code>. The prior on <code class="docutils literal notranslate"><span class="pre">v</span></code> is <code class="docutils literal notranslate"><span class="pre">p(v)</span> <span class="pre">=</span> <span class="pre">N(0,</span> <span class="pre">I)</span></code>.</p>
<p>If <a class="reference external" href="https://docs.python.org/3/library/constants.html#False" title="(in Python v3.12)"><code class="xref any docutils literal notranslate"><span class="pre">False</span></code></a>, this layer uses the non-whitened (or centred) representation,
in which we directly parameterise <code class="docutils literal notranslate"><span class="pre">q(u)</span> <span class="pre">=</span> <span class="pre">N(q_mu,</span> <span class="pre">q_sqrt</span> <span class="pre">q_sqrtᵀ)</span></code>. The
prior on <code class="docutils literal notranslate"><span class="pre">u</span></code> is <code class="docutils literal notranslate"><span class="pre">p(u)</span> <span class="pre">=</span> <span class="pre">N(0,</span> <span class="pre">Kuu)</span></code>.</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="gpflux.layers.GPLayer.num_samples">
<span class="sig-name descname"><span class="pre">num_samples</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.12)"><span class="pre">int</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.12)"><span class="pre">None</span></a></em><a class="headerlink" href="#gpflux.layers.GPLayer.num_samples" title="Permalink to this definition">#</a></dt>
<dd><p>The number of samples drawn when coercing the output distribution of
this layer to a <a class="reference external" href="https://www.tensorflow.org/api_docs/python/tf/Tensor" title="(in TensorFlow v2.4)"><code class="xref any docutils literal notranslate"><span class="pre">tf.Tensor</span></code></a>. (See <a class="reference internal" href="#gpflux.layers.GPLayer._convert_to_tensor_fn" title="gpflux.layers.GPLayer._convert_to_tensor_fn"><code class="xref py py-meth docutils literal notranslate"><span class="pre">_convert_to_tensor_fn()</span></code></a>.)</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="gpflux.layers.GPLayer.full_cov">
<span class="sig-name descname"><span class="pre">full_cov</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.12)"><span class="pre">bool</span></a></em><a class="headerlink" href="#gpflux.layers.GPLayer.full_cov" title="Permalink to this definition">#</a></dt>
<dd><p>This parameter determines the behaviour of calling this layer. If <a class="reference external" href="https://docs.python.org/3/library/constants.html#False" title="(in Python v3.12)"><code class="xref any docutils literal notranslate"><span class="pre">False</span></code></a>, only
predict or sample marginals (diagonal of covariance) with respect to inputs.
If <a class="reference external" href="https://docs.python.org/3/library/constants.html#True" title="(in Python v3.12)"><code class="xref any docutils literal notranslate"><span class="pre">True</span></code></a>, predict or sample with the full covariance over the inputs.</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="gpflux.layers.GPLayer.full_output_cov">
<span class="sig-name descname"><span class="pre">full_output_cov</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.12)"><span class="pre">bool</span></a></em><a class="headerlink" href="#gpflux.layers.GPLayer.full_output_cov" title="Permalink to this definition">#</a></dt>
<dd><p>This parameter determines the behaviour of calling this layer. If <a class="reference external" href="https://docs.python.org/3/library/constants.html#False" title="(in Python v3.12)"><code class="xref any docutils literal notranslate"><span class="pre">False</span></code></a>, only
predict or sample marginals (diagonal of covariance) with respect to outputs.
If <a class="reference external" href="https://docs.python.org/3/library/constants.html#True" title="(in Python v3.12)"><code class="xref any docutils literal notranslate"><span class="pre">True</span></code></a>, predict or sample with the full covariance over the outputs.</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="gpflux.layers.GPLayer.q_mu">
<span class="sig-name descname"><span class="pre">q_mu</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">gpflow.Parameter</span></em><a class="headerlink" href="#gpflux.layers.GPLayer.q_mu" title="Permalink to this definition">#</a></dt>
<dd><p>The mean of <code class="docutils literal notranslate"><span class="pre">q(v)</span></code> or <code class="docutils literal notranslate"><span class="pre">q(u)</span></code> (depending on whether <a class="reference internal" href="#gpflux.layers.GPLayer.whiten" title="gpflux.layers.GPLayer.whiten"><code class="xref py py-attr docutils literal notranslate"><span class="pre">whiten</span></code></a>ed
parametrisation is used).</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="gpflux.layers.GPLayer.q_sqrt">
<span class="sig-name descname"><span class="pre">q_sqrt</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">gpflow.Parameter</span></em><a class="headerlink" href="#gpflux.layers.GPLayer.q_sqrt" title="Permalink to this definition">#</a></dt>
<dd><p>The lower-triangular Cholesky factor of the covariance of <code class="docutils literal notranslate"><span class="pre">q(v)</span></code> or <code class="docutils literal notranslate"><span class="pre">q(u)</span></code>
(depending on whether <a class="reference internal" href="#gpflux.layers.GPLayer.whiten" title="gpflux.layers.GPLayer.whiten"><code class="xref py py-attr docutils literal notranslate"><span class="pre">whiten</span></code></a>ed parametrisation is used).</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="gpflux.layers.GPLayer.predict">
<span class="sig-name descname"><span class="pre">predict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">gpflow.base.TensorType</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">full_cov</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.12)"><span class="pre">bool</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">full_output_cov</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.12)"><span class="pre">bool</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://www.tensorflow.org/api_docs/python/tf/Tensor" title="(in TensorFlow v2.4)"><span class="pre">tf.Tensor</span></a><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference external" href="https://www.tensorflow.org/api_docs/python/tf/Tensor" title="(in TensorFlow v2.4)"><span class="pre">tf.Tensor</span></a><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="../../../_modules/gpflux/layers/gp_layer.html#GPLayer.predict"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#gpflux.layers.GPLayer.predict" title="Permalink to this definition">#</a></dt>
<dd><p>Make a prediction at N test inputs for the Q outputs of this layer,
including the mean function contribution.</p>
<p>The covariance and its shape is determined by <em>full_cov</em> and <em>full_output_cov</em> as follows:</p>
<table class="table">
<tbody>
<tr class="row-odd"><td><p>(co)variance shape</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">full_output_cov=False</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">full_output_cov=True</span></code></p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">full_cov=False</span></code></p></td>
<td><p>[N, Q]</p></td>
<td><p>[N, Q, Q]</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">full_cov=True</span></code></p></td>
<td><p>[Q, N, N]</p></td>
<td><p>[N, Q, N, Q]</p></td>
</tr>
</tbody>
</table>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>inputs</strong> – The inputs to predict at, with a shape of [N, D], where D is
the input dimensionality of this layer.</p></li>
<li><p><strong>full_cov</strong> – Whether to return full covariance (if <a class="reference external" href="https://docs.python.org/3/library/constants.html#True" title="(in Python v3.12)"><code class="xref any docutils literal notranslate"><span class="pre">True</span></code></a>) or
marginal variance (if <a class="reference external" href="https://docs.python.org/3/library/constants.html#False" title="(in Python v3.12)"><code class="xref any docutils literal notranslate"><span class="pre">False</span></code></a>, the default) w.r.t. inputs.</p></li>
<li><p><strong>full_output_cov</strong> – Whether to return full covariance (if <a class="reference external" href="https://docs.python.org/3/library/constants.html#True" title="(in Python v3.12)"><code class="xref any docutils literal notranslate"><span class="pre">True</span></code></a>)
or marginal variance (if <a class="reference external" href="https://docs.python.org/3/library/constants.html#False" title="(in Python v3.12)"><code class="xref any docutils literal notranslate"><span class="pre">False</span></code></a>, the default) w.r.t. outputs.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>posterior mean (shape [N, Q]) and (co)variance (shape as above) at test points</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="gpflux.layers.GPLayer.call">
<span class="sig-name descname"><span class="pre">call</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">gpflow.base.TensorType</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.12)"><span class="pre">str</span></a><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference external" href="https://www.tensorflow.org/api_docs/python/tf/Tensor" title="(in TensorFlow v2.4)"><span class="pre">tf.Tensor</span></a></span></span><a class="reference internal" href="../../../_modules/gpflux/layers/gp_layer.html#GPLayer.call"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#gpflux.layers.GPLayer.call" title="Permalink to this definition">#</a></dt>
<dd><p>The default behaviour upon calling this layer.</p>
<p>This method calls the <a class="reference external" href="https://www.tensorflow.org/probability/api_docs/python/tfp/layers/DistributionLambda" title="(in TensorFlow Probability v0.12)"><code class="xref any docutils literal notranslate"><span class="pre">tfp.layers.DistributionLambda</span></code></a> super-class
<a class="reference internal" href="#gpflux.layers.GPLayer.call" title="gpflux.layers.GPLayer.call"><code class="xref any py py-meth docutils literal notranslate"><span class="pre">call</span></code></a> method, which constructs a <a class="reference external" href="https://www.tensorflow.org/probability/api_docs/python/tfp/distributions/Distribution" title="(in TensorFlow Probability v0.12)"><code class="xref any docutils literal notranslate"><span class="pre">tfp.distributions.Distribution</span></code></a>
for the predictive distributions at the input points
(see <a class="reference internal" href="#gpflux.layers.GPLayer._make_distribution_fn" title="gpflux.layers.GPLayer._make_distribution_fn"><code class="xref py py-meth docutils literal notranslate"><span class="pre">_make_distribution_fn()</span></code></a>).
You can pass this distribution to <a class="reference external" href="https://www.tensorflow.org/api_docs/python/tf/convert_to_tensor" title="(in TensorFlow v2.4)"><code class="xref any docutils literal notranslate"><span class="pre">tf.convert_to_tensor</span></code></a>, which will return
samples from the distribution (see <a class="reference internal" href="#gpflux.layers.GPLayer._convert_to_tensor_fn" title="gpflux.layers.GPLayer._convert_to_tensor_fn"><code class="xref py py-meth docutils literal notranslate"><span class="pre">_convert_to_tensor_fn()</span></code></a>).</p>
<p>This method also adds a layer-specific loss function, given by the KL divergence between
this layer and the GP prior (scaled to per-datapoint).</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="gpflux.layers.GPLayer.prior_kl">
<span class="sig-name descname"><span class="pre">prior_kl</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference external" href="https://www.tensorflow.org/api_docs/python/tf/Tensor" title="(in TensorFlow v2.4)"><span class="pre">tf.Tensor</span></a></span></span><a class="reference internal" href="../../../_modules/gpflux/layers/gp_layer.html#GPLayer.prior_kl"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#gpflux.layers.GPLayer.prior_kl" title="Permalink to this definition">#</a></dt>
<dd><p>Returns the KL divergence <code class="docutils literal notranslate"><span class="pre">KL[q(u)∥p(u)]</span></code> from the prior <code class="docutils literal notranslate"><span class="pre">p(u)</span></code> to
the variational distribution <code class="docutils literal notranslate"><span class="pre">q(u)</span></code>.  If this layer uses the
<a class="reference internal" href="#gpflux.layers.GPLayer.whiten" title="gpflux.layers.GPLayer.whiten"><code class="xref py py-attr docutils literal notranslate"><span class="pre">whiten</span></code></a>ed representation, returns <code class="docutils literal notranslate"><span class="pre">KL[q(v)∥p(v)]</span></code>.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="gpflux.layers.GPLayer._make_distribution_fn">
<span class="sig-name descname"><span class="pre">_make_distribution_fn</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">previous_layer_outputs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">gpflow.base.TensorType</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference external" href="https://www.tensorflow.org/probability/api_docs/python/tfp/distributions/Distribution" title="(in TensorFlow Probability v0.12)"><span class="pre">tfp.distributions.Distribution</span></a></span></span><a class="reference internal" href="../../../_modules/gpflux/layers/gp_layer.html#GPLayer._make_distribution_fn"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#gpflux.layers.GPLayer._make_distribution_fn" title="Permalink to this definition">#</a></dt>
<dd><p>Construct the posterior distributions at the output points of the previous layer,
depending on <a class="reference internal" href="#gpflux.layers.GPLayer.full_cov" title="gpflux.layers.GPLayer.full_cov"><code class="xref py py-attr docutils literal notranslate"><span class="pre">full_cov</span></code></a> and <a class="reference internal" href="#gpflux.layers.GPLayer.full_output_cov" title="gpflux.layers.GPLayer.full_output_cov"><code class="xref py py-attr docutils literal notranslate"><span class="pre">full_output_cov</span></code></a>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>previous_layer_outputs</strong> – The output from the previous layer,
which should be coercible to a <a class="reference external" href="https://www.tensorflow.org/api_docs/python/tf/Tensor" title="(in TensorFlow v2.4)"><code class="xref any docutils literal notranslate"><span class="pre">tf.Tensor</span></code></a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="gpflux.layers.GPLayer._convert_to_tensor_fn">
<span class="sig-name descname"><span class="pre">_convert_to_tensor_fn</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">distribution</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://www.tensorflow.org/probability/api_docs/python/tfp/distributions/Distribution" title="(in TensorFlow Probability v0.12)"><span class="pre">tfp.distributions.Distribution</span></a></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference external" href="https://www.tensorflow.org/api_docs/python/tf/Tensor" title="(in TensorFlow v2.4)"><span class="pre">tf.Tensor</span></a></span></span><a class="reference internal" href="../../../_modules/gpflux/layers/gp_layer.html#GPLayer._convert_to_tensor_fn"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#gpflux.layers.GPLayer._convert_to_tensor_fn" title="Permalink to this definition">#</a></dt>
<dd><p>Convert the predictive distributions at the input points (see
<a class="reference internal" href="#gpflux.layers.GPLayer._make_distribution_fn" title="gpflux.layers.GPLayer._make_distribution_fn"><code class="xref py py-meth docutils literal notranslate"><span class="pre">_make_distribution_fn()</span></code></a>) to a tensor of <a class="reference internal" href="#gpflux.layers.GPLayer.num_samples" title="gpflux.layers.GPLayer.num_samples"><code class="xref py py-attr docutils literal notranslate"><span class="pre">num_samples</span></code></a>
samples from that distribution.
Whether the samples are correlated or marginal (uncorrelated) depends
on <a class="reference internal" href="#gpflux.layers.GPLayer.full_cov" title="gpflux.layers.GPLayer.full_cov"><code class="xref py py-attr docutils literal notranslate"><span class="pre">full_cov</span></code></a> and <a class="reference internal" href="#gpflux.layers.GPLayer.full_output_cov" title="gpflux.layers.GPLayer.full_output_cov"><code class="xref py py-attr docutils literal notranslate"><span class="pre">full_output_cov</span></code></a>.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="gpflux.layers.GPLayer.sample">
<span class="sig-name descname"><span class="pre">sample</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="../sampling/sample/index.html#gpflux.sampling.sample.Sample" title="gpflux.sampling.sample.Sample"><span class="pre">gpflux.sampling.sample.Sample</span></a></span></span><a class="reference internal" href="../../../_modules/gpflux/layers/gp_layer.html#GPLayer.sample"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#gpflux.layers.GPLayer.sample" title="Permalink to this definition">#</a></dt>
<dd><div class="admonition-todo admonition" id="id1">
<p class="admonition-title">Todo</p>
<p>TODO: Document this.</p>
</div>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="gpflux.layers.LatentVariableLayer">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">LatentVariableLayer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prior</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://www.tensorflow.org/probability/api_docs/python/tfp/distributions/Distribution" title="(in TensorFlow Probability v0.12)"><span class="pre">tfp.distributions.Distribution</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">encoder</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">gpflow.keras.tf_keras.layers.Layer</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">compositor</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">gpflow.keras.tf_keras.layers.Layer</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.12)"><span class="pre">None</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">name</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.12)"><span class="pre">str</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.12)"><span class="pre">None</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/gpflux/layers/latent_variable_layer.html#LatentVariableLayer"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#gpflux.layers.LatentVariableLayer" title="Permalink to this definition">#</a></dt>
<dd><p>Bases: <a class="reference internal" href="#gpflux.layers.LayerWithObservations" title="gpflux.layers.LayerWithObservations"><code class="xref py py-obj docutils literal notranslate"><span class="pre">LayerWithObservations</span></code></a></p>
<p>A latent variable layer, with amortized mean-field variational inference.</p>
<p>The latent variable is distribution-agnostic, but assumes a variational posterior
that is fully factorised and is of the same distribution family as the prior.</p>
<p>This class is used by models as described in <span id="id2">[<a class="reference internal" href="../../../index.html#id7" title="Vincent Dutordoir, Hugh Salimbeni, James Hensman, and Marc Deisenroth. Gaussian process conditional density estimation. In Advances in Neural Information Processing Systems. 2018.">DSHD18</a>, <a class="reference internal" href="../../../index.html#id8" title="Hugh Salimbeni, Vincent Dutordoir, James Hensman, and Marc Deisenroth. Deep Gaussian processes with importance-weighted variational inference. In International Conference on Machine Learning. 2019.">SDHD19</a>]</span>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prior</strong> – A distribution that represents the <a class="reference internal" href="#gpflux.layers.LatentVariableLayer.prior" title="gpflux.layers.LatentVariableLayer.prior"><code class="xref py py-attr docutils literal notranslate"><span class="pre">prior</span></code></a> over the latent variable.</p></li>
<li><p><strong>encoder</strong> – A layer which is passed the concatenated observation inputs
and targets, and returns the appropriate parameters for the approximate
posterior distribution; see <a class="reference internal" href="#gpflux.layers.LatentVariableLayer.encoder" title="gpflux.layers.LatentVariableLayer.encoder"><code class="xref py py-attr docutils literal notranslate"><span class="pre">encoder</span></code></a>.</p></li>
<li><p><strong>compositor</strong> – A layer that combines layer inputs and latent variable
samples into a single tensor; see <a class="reference internal" href="#gpflux.layers.LatentVariableLayer.compositor" title="gpflux.layers.LatentVariableLayer.compositor"><code class="xref py py-attr docutils literal notranslate"><span class="pre">compositor</span></code></a>. If you do not specify a value for
this parameter, the default is
<code class="docutils literal notranslate"><span class="pre">tf.keras.layers.Concatenate(axis=-1,</span> <span class="pre">dtype=default_float())</span></code>. Note that you should
set <code class="docutils literal notranslate"><span class="pre">dtype</span></code> of the layer to GPflow’s default dtype as in
<code class="xref py py-meth docutils literal notranslate"><span class="pre">default_float()</span></code>.</p></li>
<li><p><strong>name</strong> – The name of this layer (passed through to <a class="reference external" href="https://www.tensorflow.org/api_docs/python/tf/keras/layers/Layer" title="(in TensorFlow v2.4)"><code class="xref any docutils literal notranslate"><span class="pre">tf.keras.layers.Layer</span></code></a>).</p></li>
</ul>
</dd>
</dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="gpflux.layers.LatentVariableLayer.prior">
<span class="sig-name descname"><span class="pre">prior</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://www.tensorflow.org/probability/api_docs/python/tfp/distributions/Distribution" title="(in TensorFlow Probability v0.12)"><span class="pre">tfp.distributions.Distribution</span></a></em><a class="headerlink" href="#gpflux.layers.LatentVariableLayer.prior" title="Permalink to this definition">#</a></dt>
<dd><p>The prior distribution for the latent variables.</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="gpflux.layers.LatentVariableLayer.encoder">
<span class="sig-name descname"><span class="pre">encoder</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">gpflow.keras.tf_keras.layers.Layer</span></em><a class="headerlink" href="#gpflux.layers.LatentVariableLayer.encoder" title="Permalink to this definition">#</a></dt>
<dd><p>An encoder that maps from a concatenation of inputs and targets to the
parameters of the approximate posterior distribution of the corresponding
latent variables.</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="gpflux.layers.LatentVariableLayer.compositor">
<span class="sig-name descname"><span class="pre">compositor</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">gpflow.keras.tf_keras.layers.Layer</span></em><a class="headerlink" href="#gpflux.layers.LatentVariableLayer.compositor" title="Permalink to this definition">#</a></dt>
<dd><p>A layer that takes as input the two-element <code class="docutils literal notranslate"><span class="pre">[layer_inputs,</span> <span class="pre">latent_variable_samples]</span></code> list
and combines the elements into a single output tensor.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="gpflux.layers.LatentVariableLayer.call">
<span class="sig-name descname"><span class="pre">call</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">layer_inputs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">gpflow.base.TensorType</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">observations</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">gpflux.types.ObservationType</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.12)"><span class="pre">None</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">training</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.12)"><span class="pre">bool</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.12)"><span class="pre">None</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">seed</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.12)"><span class="pre">int</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.12)"><span class="pre">None</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference external" href="https://www.tensorflow.org/api_docs/python/tf/Tensor" title="(in TensorFlow v2.4)"><span class="pre">tf.Tensor</span></a></span></span><a class="reference internal" href="../../../_modules/gpflux/layers/latent_variable_layer.html#LatentVariableLayer.call"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#gpflux.layers.LatentVariableLayer.call" title="Permalink to this definition">#</a></dt>
<dd><p>Sample the latent variables and compose them with the layer input.</p>
<p>When training, draw a sample of the latent variable from the posterior,
whose distribution is parameterised by the encoder mapping from the data.
Also add a KL divergence [posterior∥prior] to the losses.</p>
<p>When not training, draw a sample of the latent variable from the prior.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>layer_inputs</strong> – The output of the previous layer.</p></li>
<li><p><strong>observations</strong> – The <code class="docutils literal notranslate"><span class="pre">[inputs,</span> <span class="pre">targets]</span></code>, with the shapes <code class="docutils literal notranslate"><span class="pre">[batch</span> <span class="pre">size,</span> <span class="pre">Din]</span></code>
and <code class="docutils literal notranslate"><span class="pre">[batch</span> <span class="pre">size,</span> <span class="pre">Dout]</span></code> respectively. This parameter should be passed only when in
training mode.</p></li>
<li><p><strong>training</strong> – The training mode indicator.</p></li>
<li><p><strong>seed</strong> – A random seed for the sampling operation.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Samples of the latent variable composed with the layer inputs through the
<a class="reference internal" href="#gpflux.layers.LatentVariableLayer.compositor" title="gpflux.layers.LatentVariableLayer.compositor"><code class="xref py py-attr docutils literal notranslate"><span class="pre">compositor</span></code></a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="gpflux.layers.LatentVariableLayer._inference_posteriors">
<span class="sig-name descname"><span class="pre">_inference_posteriors</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">observations</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">gpflux.types.ObservationType</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">training</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.12)"><span class="pre">bool</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.12)"><span class="pre">None</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference external" href="https://www.tensorflow.org/probability/api_docs/python/tfp/distributions/Distribution" title="(in TensorFlow Probability v0.12)"><span class="pre">tfp.distributions.Distribution</span></a></span></span><a class="reference internal" href="../../../_modules/gpflux/layers/latent_variable_layer.html#LatentVariableLayer._inference_posteriors"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#gpflux.layers.LatentVariableLayer._inference_posteriors" title="Permalink to this definition">#</a></dt>
<dd><p>Return the posterior distributions parametrised by the <a class="reference internal" href="#gpflux.layers.LatentVariableLayer.encoder" title="gpflux.layers.LatentVariableLayer.encoder"><code class="xref py py-attr docutils literal notranslate"><span class="pre">encoder</span></code></a>, which gets called
with the concatenation of the inputs and targets in the <em>observations</em> argument.</p>
<div class="admonition-todo admonition" id="id3">
<p class="admonition-title">Todo</p>
<p>We might want to change encoders to have a
<a class="reference external" href="https://www.tensorflow.org/probability/api_docs/python/tfp/layers/DistributionLambda" title="(in TensorFlow Probability v0.12)"><code class="xref any docutils literal notranslate"><span class="pre">tfp.layers.DistributionLambda</span></code></a> final layer that directly returns the
appropriately parameterised distributions object.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>observations</strong> – The <code class="docutils literal notranslate"><span class="pre">[inputs,</span> <span class="pre">targets]</span></code>, with the shapes <code class="docutils literal notranslate"><span class="pre">[batch</span> <span class="pre">size,</span> <span class="pre">Din]</span></code>
and <code class="docutils literal notranslate"><span class="pre">[batch</span> <span class="pre">size,</span> <span class="pre">Dout]</span></code> respectively.</p></li>
<li><p><strong>training</strong> – The training mode indicator (passed through to the <a class="reference internal" href="#gpflux.layers.LatentVariableLayer.encoder" title="gpflux.layers.LatentVariableLayer.encoder"><code class="xref py py-attr docutils literal notranslate"><span class="pre">encoder</span></code></a>’s call).</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The posterior distributions object.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="gpflux.layers.LatentVariableLayer._inference_latent_samples_and_loss">
<span class="sig-name descname"><span class="pre">_inference_latent_samples_and_loss</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">layer_inputs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">gpflow.base.TensorType</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">observations</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">gpflux.types.ObservationType</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">seed</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.12)"><span class="pre">int</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.12)"><span class="pre">None</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://www.tensorflow.org/api_docs/python/tf/Tensor" title="(in TensorFlow v2.4)"><span class="pre">tf.Tensor</span></a><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference external" href="https://www.tensorflow.org/api_docs/python/tf/Tensor" title="(in TensorFlow v2.4)"><span class="pre">tf.Tensor</span></a><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="../../../_modules/gpflux/layers/latent_variable_layer.html#LatentVariableLayer._inference_latent_samples_and_loss"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#gpflux.layers.LatentVariableLayer._inference_latent_samples_and_loss" title="Permalink to this definition">#</a></dt>
<dd><p>Sample latent variables during the <em>training</em> forward pass, hence requiring
the observations. Also return the KL loss per datapoint.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>layer_inputs</strong> – The output of the previous layer _(unused)_.</p></li>
<li><p><strong>observations</strong> – The <code class="docutils literal notranslate"><span class="pre">[inputs,</span> <span class="pre">targets]</span></code>, with the shapes <code class="docutils literal notranslate"><span class="pre">[batch</span> <span class="pre">size,</span> <span class="pre">Din]</span></code>
and <code class="docutils literal notranslate"><span class="pre">[batch</span> <span class="pre">size,</span> <span class="pre">Dout]</span></code> respectively.</p></li>
<li><p><strong>seed</strong> – A random seed for the sampling operation.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The samples and the loss-per-datapoint.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="gpflux.layers.LatentVariableLayer._prediction_latent_samples">
<span class="sig-name descname"><span class="pre">_prediction_latent_samples</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">layer_inputs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">gpflow.base.TensorType</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">seed</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.12)"><span class="pre">int</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.12)"><span class="pre">None</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference external" href="https://www.tensorflow.org/api_docs/python/tf/Tensor" title="(in TensorFlow v2.4)"><span class="pre">tf.Tensor</span></a></span></span><a class="reference internal" href="../../../_modules/gpflux/layers/latent_variable_layer.html#LatentVariableLayer._prediction_latent_samples"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#gpflux.layers.LatentVariableLayer._prediction_latent_samples" title="Permalink to this definition">#</a></dt>
<dd><p>Sample latent variables during the <em>prediction</em> forward pass, only
depending on the shape of this layer’s inputs.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>layer_inputs</strong> – The output of the previous layer (for determining batch shape).</p></li>
<li><p><strong>seed</strong> – A random seed for the sampling operation.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The samples.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="gpflux.layers.LatentVariableLayer._local_kls">
<span class="sig-name descname"><span class="pre">_local_kls</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">posteriors</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://www.tensorflow.org/probability/api_docs/python/tfp/distributions/Distribution" title="(in TensorFlow Probability v0.12)"><span class="pre">tfp.distributions.Distribution</span></a></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference external" href="https://www.tensorflow.org/api_docs/python/tf/Tensor" title="(in TensorFlow v2.4)"><span class="pre">tf.Tensor</span></a></span></span><a class="reference internal" href="../../../_modules/gpflux/layers/latent_variable_layer.html#LatentVariableLayer._local_kls"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#gpflux.layers.LatentVariableLayer._local_kls" title="Permalink to this definition">#</a></dt>
<dd><p>Compute the KL divergences [posteriors∥prior].</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>posteriors</strong> – A distribution that represents the approximate posteriors.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The KL divergences from the prior for each of the posteriors.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="gpflux.layers.LayerWithObservations">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">LayerWithObservations</span></span><a class="reference internal" href="../../../_modules/gpflux/layers/latent_variable_layer.html#LayerWithObservations"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#gpflux.layers.LayerWithObservations" title="Permalink to this definition">#</a></dt>
<dd><p>Bases: <a class="reference internal" href="trackable_layer/index.html#gpflux.layers.trackable_layer.TrackableLayer" title="gpflux.layers.trackable_layer.TrackableLayer"><code class="xref py py-obj docutils literal notranslate"><span class="pre">gpflux.layers.trackable_layer.TrackableLayer</span></code></a></p>
<p>By inheriting from this class, Layers indicate that their <a class="reference internal" href="#gpflux.layers.LayerWithObservations.call" title="gpflux.layers.LayerWithObservations.call"><code class="xref py py-meth docutils literal notranslate"><span class="pre">call()</span></code></a>
method takes a second <em>observations</em> argument after the customary
<em>layer_inputs</em> argument.</p>
<p>This is used to distinguish which layers (unlike most standard Keras
layers) require the original inputs and/or targets during training.
For example, it is used by the amortized variational inference in the
<a class="reference internal" href="#gpflux.layers.LatentVariableLayer" title="gpflux.layers.LatentVariableLayer"><code class="xref py py-class docutils literal notranslate"><span class="pre">LatentVariableLayer</span></code></a>.</p>
<dl class="py method">
<dt class="sig sig-object py" id="gpflux.layers.LayerWithObservations.call">
<em class="property"><span class="pre">abstract</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">call</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">layer_inputs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">gpflow.base.TensorType</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">observations</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">gpflux.types.ObservationType</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.12)"><span class="pre">None</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">training</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.12)"><span class="pre">bool</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.12)"><span class="pre">None</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference external" href="https://www.tensorflow.org/api_docs/python/tf/Tensor" title="(in TensorFlow v2.4)"><span class="pre">tf.Tensor</span></a></span></span><a class="reference internal" href="../../../_modules/gpflux/layers/latent_variable_layer.html#LayerWithObservations.call"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#gpflux.layers.LayerWithObservations.call" title="Permalink to this definition">#</a></dt>
<dd><p>The <a class="reference internal" href="#gpflux.layers.LayerWithObservations.call" title="gpflux.layers.LayerWithObservations.call"><code class="xref py py-meth docutils literal notranslate"><span class="pre">call()</span></code></a> method of <a class="reference internal" href="#gpflux.layers.LayerWithObservations" title="gpflux.layers.LayerWithObservations"><code class="xref any py py-class docutils literal notranslate"><span class="pre">LayerWithObservations</span></code></a> subclasses should
accept a second argument, <em>observations</em>. In training mode, this will
be the <code class="docutils literal notranslate"><span class="pre">[inputs,</span> <span class="pre">targets]</span></code> of the training points; otherwise, it is <a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.12)"><code class="xref any docutils literal notranslate"><span class="pre">None</span></code></a>.</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="gpflux.layers.LikelihoodLayer">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">LikelihoodLayer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">likelihood</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">gpflow.likelihoods.Likelihood</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/gpflux/layers/likelihood_layer.html#LikelihoodLayer"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#gpflux.layers.LikelihoodLayer" title="Permalink to this definition">#</a></dt>
<dd><p>Bases: <a class="reference internal" href="trackable_layer/index.html#gpflux.layers.trackable_layer.TrackableLayer" title="gpflux.layers.trackable_layer.TrackableLayer"><code class="xref py py-obj docutils literal notranslate"><span class="pre">gpflux.layers.trackable_layer.TrackableLayer</span></code></a></p>
<p>A Keras layer that wraps a GPflow <code class="xref py py-class docutils literal notranslate"><span class="pre">Likelihood</span></code>. This layer expects a
<a class="reference external" href="https://www.tensorflow.org/probability/api_docs/python/tfp/distributions/MultivariateNormalDiag" title="(in TensorFlow Probability v0.12)"><code class="xref any docutils literal notranslate"><span class="pre">tfp.distributions.MultivariateNormalDiag</span></code></a> as its input, describing <code class="docutils literal notranslate"><span class="pre">q(f)</span></code>.
When training, calling this class computes the negative variational expectation
<span class="math notranslate nohighlight">\(-\mathbb{E}_{q(f)}[\log p(y|f)]\)</span> and adds it as a layer loss.
When not training, it computes the mean and variance of <code class="docutils literal notranslate"><span class="pre">y</span></code> under <code class="docutils literal notranslate"><span class="pre">q(f)</span></code>
using <code class="xref py py-meth docutils literal notranslate"><span class="pre">predict_mean_and_var()</span></code>.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Use <strong>either</strong> this <a class="reference internal" href="#gpflux.layers.LikelihoodLayer" title="gpflux.layers.LikelihoodLayer"><code class="xref any py py-class docutils literal notranslate"><span class="pre">LikelihoodLayer</span></code></a> (together with
<a class="reference internal" href="../models/index.html#gpflux.models.DeepGP" title="gpflux.models.DeepGP"><code class="xref any py py-class docutils literal notranslate"><span class="pre">gpflux.models.DeepGP</span></code></a>) <strong>or</strong> <a class="reference internal" href="../losses/index.html#gpflux.losses.LikelihoodLoss" title="gpflux.losses.LikelihoodLoss"><code class="xref any py py-class docutils literal notranslate"><span class="pre">LikelihoodLoss</span></code></a> (e.g. together with a
<a class="reference external" href="https://www.tensorflow.org/api_docs/python/tf/keras/Sequential" title="(in TensorFlow v2.4)"><code class="xref any docutils literal notranslate"><span class="pre">tf.keras.Sequential</span></code></a> model). Do <strong>not</strong> use both at once because
this would add the loss twice.</p>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="gpflux.layers.LikelihoodLayer.call">
<span class="sig-name descname"><span class="pre">call</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://www.tensorflow.org/probability/api_docs/python/tfp/distributions/MultivariateNormalDiag" title="(in TensorFlow Probability v0.12)"><span class="pre">tfp.distributions.MultivariateNormalDiag</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">targets</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">gpflow.base.TensorType</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.12)"><span class="pre">None</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">training</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.12)"><span class="pre">bool</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="likelihood_layer/index.html#gpflux.layers.likelihood_layer.LikelihoodOutputs" title="gpflux.layers.likelihood_layer.LikelihoodOutputs"><span class="pre">LikelihoodOutputs</span></a></span></span><a class="reference internal" href="../../../_modules/gpflux/layers/likelihood_layer.html#LikelihoodLayer.call"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#gpflux.layers.LikelihoodLayer.call" title="Permalink to this definition">#</a></dt>
<dd><p>When training (<code class="docutils literal notranslate"><span class="pre">training=True</span></code>), this method computes variational expectations
(data-fit loss) and adds this information as a layer loss.
When testing (the default), it computes the posterior mean and variance of <code class="docutils literal notranslate"><span class="pre">y</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>inputs</strong> – The output distribution of the previous layer. This is currently
expected to be a <a class="reference external" href="https://www.tensorflow.org/probability/api_docs/python/tfp/distributions/MultivariateNormalDiag" title="(in TensorFlow Probability v0.12)"><code class="xref py py-class docutils literal notranslate"><span class="pre">MultivariateNormalDiag</span></code></a>;
that is, the preceding <a class="reference internal" href="#gpflux.layers.GPLayer" title="gpflux.layers.GPLayer"><code class="xref py py-class docutils literal notranslate"><span class="pre">GPLayer</span></code></a> should have
<code class="docutils literal notranslate"><span class="pre">full_cov=full_output_cov=False</span></code>.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>a <a class="reference internal" href="likelihood_layer/index.html#gpflux.layers.likelihood_layer.LikelihoodOutputs" title="gpflux.layers.likelihood_layer.LikelihoodOutputs"><code class="xref any py py-class docutils literal notranslate"><span class="pre">LikelihoodOutputs</span></code></a> tuple with the mean and variance of <code class="docutils literal notranslate"><span class="pre">f</span></code> and,
if not training, the mean and variance of <code class="docutils literal notranslate"><span class="pre">y</span></code>.</p>
</dd>
</dl>
<div class="admonition-todo admonition" id="id4">
<p class="admonition-title">Todo</p>
<p>Turn this layer into a
<a class="reference external" href="https://www.tensorflow.org/probability/api_docs/python/tfp/layers/DistributionLambda" title="(in TensorFlow Probability v0.12)"><code class="xref py py-class docutils literal notranslate"><span class="pre">DistributionLambda</span></code></a> as well and return the
correct <a class="reference external" href="https://www.tensorflow.org/probability/api_docs/python/tfp/distributions/Distribution" title="(in TensorFlow Probability v0.12)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Distribution</span></code></a> instead of a tuple
containing mean and variance only.</p>
</div>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="gpflux.layers.TrackableLayer">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">TrackableLayer</span></span><a class="reference internal" href="../../../_modules/gpflux/layers/trackable_layer.html#TrackableLayer"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#gpflux.layers.TrackableLayer" title="Permalink to this definition">#</a></dt>
<dd><p>Bases: <code class="xref py py-obj docutils literal notranslate"><span class="pre">gpflow.keras.tf_keras.layers.Layer</span></code></p>
<p>With the release of TensorFlow 2.5, our TrackableLayer workaround is no
longer needed.  See <a class="github reference external" href="https://github.com/Prowler-io/gpflux/issues/189">Prowler-io/gpflux#189</a>.
Will be removed in GPflux version 1.0.0</p>
</dd></dl>

</section>
</section>


                </article>
              
              
              
              
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">

  <div class="sidebar-secondary-item">

  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> On this page
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#subpackages">Subpackages</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#submodules">Submodules</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#package-contents">Package Contents</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#gpflux.layers.BayesianDenseLayer"><code class="docutils literal notranslate"><span class="pre">BayesianDenseLayer</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#gpflux.layers.BayesianDenseLayer.build"><code class="docutils literal notranslate"><span class="pre">BayesianDenseLayer.build()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#gpflux.layers.BayesianDenseLayer.predict_samples"><code class="docutils literal notranslate"><span class="pre">BayesianDenseLayer.predict_samples()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#gpflux.layers.BayesianDenseLayer.call"><code class="docutils literal notranslate"><span class="pre">BayesianDenseLayer.call()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#gpflux.layers.BayesianDenseLayer.prior_kl"><code class="docutils literal notranslate"><span class="pre">BayesianDenseLayer.prior_kl()</span></code></a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#gpflux.layers.GPLayer"><code class="docutils literal notranslate"><span class="pre">GPLayer</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#gpflux.layers.GPLayer.num_data"><code class="docutils literal notranslate"><span class="pre">GPLayer.num_data</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#gpflux.layers.GPLayer.whiten"><code class="docutils literal notranslate"><span class="pre">GPLayer.whiten</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#gpflux.layers.GPLayer.num_samples"><code class="docutils literal notranslate"><span class="pre">GPLayer.num_samples</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#gpflux.layers.GPLayer.full_cov"><code class="docutils literal notranslate"><span class="pre">GPLayer.full_cov</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#gpflux.layers.GPLayer.full_output_cov"><code class="docutils literal notranslate"><span class="pre">GPLayer.full_output_cov</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#gpflux.layers.GPLayer.q_mu"><code class="docutils literal notranslate"><span class="pre">GPLayer.q_mu</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#gpflux.layers.GPLayer.q_sqrt"><code class="docutils literal notranslate"><span class="pre">GPLayer.q_sqrt</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#gpflux.layers.GPLayer.predict"><code class="docutils literal notranslate"><span class="pre">GPLayer.predict()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#gpflux.layers.GPLayer.call"><code class="docutils literal notranslate"><span class="pre">GPLayer.call()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#gpflux.layers.GPLayer.prior_kl"><code class="docutils literal notranslate"><span class="pre">GPLayer.prior_kl()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#gpflux.layers.GPLayer._make_distribution_fn"><code class="docutils literal notranslate"><span class="pre">GPLayer._make_distribution_fn()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#gpflux.layers.GPLayer._convert_to_tensor_fn"><code class="docutils literal notranslate"><span class="pre">GPLayer._convert_to_tensor_fn()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#gpflux.layers.GPLayer.sample"><code class="docutils literal notranslate"><span class="pre">GPLayer.sample()</span></code></a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#gpflux.layers.LatentVariableLayer"><code class="docutils literal notranslate"><span class="pre">LatentVariableLayer</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#gpflux.layers.LatentVariableLayer.prior"><code class="docutils literal notranslate"><span class="pre">LatentVariableLayer.prior</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#gpflux.layers.LatentVariableLayer.encoder"><code class="docutils literal notranslate"><span class="pre">LatentVariableLayer.encoder</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#gpflux.layers.LatentVariableLayer.compositor"><code class="docutils literal notranslate"><span class="pre">LatentVariableLayer.compositor</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#gpflux.layers.LatentVariableLayer.call"><code class="docutils literal notranslate"><span class="pre">LatentVariableLayer.call()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#gpflux.layers.LatentVariableLayer._inference_posteriors"><code class="docutils literal notranslate"><span class="pre">LatentVariableLayer._inference_posteriors()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#gpflux.layers.LatentVariableLayer._inference_latent_samples_and_loss"><code class="docutils literal notranslate"><span class="pre">LatentVariableLayer._inference_latent_samples_and_loss()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#gpflux.layers.LatentVariableLayer._prediction_latent_samples"><code class="docutils literal notranslate"><span class="pre">LatentVariableLayer._prediction_latent_samples()</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#gpflux.layers.LatentVariableLayer._local_kls"><code class="docutils literal notranslate"><span class="pre">LatentVariableLayer._local_kls()</span></code></a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#gpflux.layers.LayerWithObservations"><code class="docutils literal notranslate"><span class="pre">LayerWithObservations</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#gpflux.layers.LayerWithObservations.call"><code class="docutils literal notranslate"><span class="pre">LayerWithObservations.call()</span></code></a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#gpflux.layers.LikelihoodLayer"><code class="docutils literal notranslate"><span class="pre">LikelihoodLayer</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#gpflux.layers.LikelihoodLayer.call"><code class="docutils literal notranslate"><span class="pre">LikelihoodLayer.call()</span></code></a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#gpflux.layers.TrackableLayer"><code class="docutils literal notranslate"><span class="pre">TrackableLayer</span></code></a></li>
</ul>
</li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
          </footer>
        
      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../../_static/scripts/bootstrap.js?digest=5b4479735964841361fd"></script>
<script src="../../../_static/scripts/pydata-sphinx-theme.js?digest=5b4479735964841361fd"></script>

  <footer class="bd-footer">
<div class="bd-footer__inner bd-page-width">
  
    <div class="footer-items__start">
      
        <div class="footer-item">

  <p class="copyright">
    
      © Copyright Copyright 2021 The GPflux Contributors

Licensed under the Apache License, Version 2.0
.
      <br/>
    
  </p>
</div>
      
        <div class="footer-item">

  <p class="sphinx-version">
    Created using <a href="https://www.sphinx-doc.org/">Sphinx</a> 7.1.2.
    <br/>
  </p>
</div>
      
    </div>
  
  
  
    <div class="footer-items__end">
      
        <div class="footer-item">
<p class="theme-version">
  Built with the <a href="https://pydata-sphinx-theme.readthedocs.io/en/stable/index.html">PyData Sphinx Theme</a> 0.14.4.
</p></div>
      
    </div>
  
</div>

  </footer>
  </body>
</html>