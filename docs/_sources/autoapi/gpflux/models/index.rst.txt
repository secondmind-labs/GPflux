gpflux.models
=============

.. py:module:: gpflux.models

.. autoapi-nested-parse::

   Base model classes implemented in GPflux



Submodules
----------

.. toctree::
   :maxdepth: 1

   /autoapi/gpflux/models/deep_gp/index




Package Contents
----------------

.. py:class:: DeepGP(f_layers: List[gpflow.keras.tf_keras.layers.Layer], likelihood: Union[gpflux.layers.LikelihoodLayer, gpflow.likelihoods.Likelihood], *, input_dim: Optional[int] = None, target_dim: Optional[int] = None, default_model_class: Type[gpflow.keras.tf_keras.Model] = tf_keras.Model, num_data: Optional[int] = None)

   Bases: :py:obj:`gpflow.base.Module`


   This class combines a sequential function model ``f(x) = fₙ(⋯ (f₂(f₁(x))))``
   and a likelihood ``p(y|f)``.

   Layers might depend on both inputs x and targets y during training by
   inheriting from :class:`~gpflux.layers.LayerWithObservations`; those will
   be passed the argument ``observations=[inputs, targets]``.

   When data is used with methods in this class (e.g. :meth:`predict_f` method), it needs to
   be with ``dtype`` corresponding to GPflow's default dtype as in :meth:`~gpflow.default_float()`.

   .. note:: This class is **not** a `tf.keras.Model` subclass itself. To access
      Keras features, call either :meth:`as_training_model` or :meth:`as_prediction_model`
      (depending on the use-case) to create a `tf.keras.Model` instance. See the method docstrings
      for more details.

   :param f_layers: The layers ``[f₁, f₂, …, fₙ]`` describing the latent
       function ``f(x) = fₙ(⋯ (f₂(f₁(x))))``.
   :param likelihood: The layer for the likelihood ``p(y|f)``. If this is a
       GPflow likelihood, it will be wrapped in a :class:`~gpflux.layers.LikelihoodLayer`.
       Alternatively, you can provide a :class:`~gpflux.layers.LikelihoodLayer` explicitly.
   :param input_dim: The input dimensionality.
   :param target_dim: The target dimensionality.
   :param default_model_class: The default for the *model_class* argument of
       :meth:`as_training_model` and :meth:`as_prediction_model`;
       see the :attr:`default_model_class` attribute.
   :param num_data: The number of points in the training dataset; see the
       :attr:`num_data` attribute.
       If you do not specify a value for this parameter explicitly, it is automatically
       detected from the :attr:`~gpflux.layers.GPLayer.num_data` attribute in the GP layers.


   .. py:attribute:: f_layers
      :type:  List[gpflow.keras.tf_keras.layers.Layer]

      A list of all layers in this DeepGP (just :attr:`likelihood_layer` is separate). 



   .. py:attribute:: likelihood_layer
      :type:  gpflux.layers.LikelihoodLayer

      The likelihood layer. 



   .. py:attribute:: default_model_class
      :type:  Type[gpflow.keras.tf_keras.Model]

      The default for the *model_class* argument of :meth:`as_training_model` and
      :meth:`as_prediction_model`. This must have the same semantics as `tf.keras.Model`,
      that is, it must accept a list of inputs and an output. This could be
      `tf.keras.Model` itself or `gpflux.optimization.NatGradModel` (but not, for
      example, `tf.keras.Sequential`).



   .. py:attribute:: num_data
      :type:  int

      The number of points in the training dataset. This information is used to
      obtain correct scaling between the data-fit and the KL term in the evidence
      lower bound (:meth:`elbo`).



   .. py:method:: _validate_num_data(f_layers: List[gpflow.keras.tf_keras.layers.Layer], num_data: Optional[int] = None) -> int
      :staticmethod:


      Check that the :attr:`~gpflux.layers.gp_layer.GPLayer.num_data`
      attributes of all layers in *f_layers* are consistent with each other
      and with the (optional) *num_data* argument.

      :returns: The validated number of datapoints.



   .. py:method:: _validate_dtype(x: gpflow.base.TensorType) -> None
      :staticmethod:


      Check that data ``x`` is of correct ``dtype``, corresponding to GPflow's default dtype as
      defined by :meth:`~gpflow.default_float()`.

      :raise ValueError: If ``x`` is of incorrect ``dtype``.



   .. py:method:: _evaluate_deep_gp(inputs: gpflow.base.TensorType, targets: Optional[gpflow.base.TensorType], training: Optional[bool] = None) -> tensorflow.Tensor

      Evaluate ``f(x) = fₙ(⋯ (f₂(f₁(x))))`` on the *inputs* argument.

      Layers that inherit from :class:`~gpflux.layers.LayerWithObservations`
      are passed the additional keyword argument ``observations=[inputs,
      targets]`` if *targets* contains a value, or ``observations=None`` when
      *targets* is `None`.



   .. py:method:: _evaluate_likelihood(f_outputs: gpflow.base.TensorType, targets: Optional[gpflow.base.TensorType], training: Optional[bool] = None) -> tensorflow.Tensor

      Call the `likelihood_layer` on *f_outputs*, which adds the
      corresponding layer loss when training.



   .. py:method:: predict_f(inputs: gpflow.base.TensorType) -> Tuple[tensorflow.Tensor, tensorflow.Tensor]

      :returns: The mean and variance (not the scale!) of ``f``, for compatibility with GPflow
         models.
      :raise ValueError: If ``x`` is of incorrect ``dtype``.

      .. note:: This method does **not** support ``full_cov`` or ``full_output_cov``.



   .. py:method:: elbo(data: Tuple[gpflow.base.TensorType, gpflow.base.TensorType]) -> tensorflow.Tensor

      :returns: The ELBO (not the per-datapoint loss!), for compatibility with GPflow models.



   .. py:method:: as_training_model(model_class: Optional[Type[gpflow.keras.tf_keras.Model]] = None) -> gpflow.keras.tf_keras.Model

      Construct a `tf.keras.Model` instance that requires you to provide both ``inputs``
      and ``targets`` to its call. This information is required for
      training the model, because the ``targets`` need to be passed to the `likelihood_layer` (and
      to :class:`~gpflux.layers.LayerWithObservations` instances such as
      :class:`~gpflux.layers.LatentVariableLayer`\ s, if present).

      When compiling the returned model, do **not** provide any additional
      losses (this is handled by the :attr:`likelihood_layer`).

      Train with

      .. code-block:: python

          model.compile(optimizer)  # do NOT pass a loss here
          model.fit({"inputs": X, "targets": Y}, ...)

      See `Keras's Endpoint layer pattern
      <https://keras.io/examples/keras_recipes/endpoint_layer_pattern/>`_
      for more details.

      .. note:: Use `as_prediction_model` if you want only to predict, and do not want to pass in
         a dummy array for the targets.

      :param model_class: The model class to use; overrides `default_model_class`.



   .. py:method:: as_prediction_model(model_class: Optional[Type[gpflow.keras.tf_keras.Model]] = None) -> gpflow.keras.tf_keras.Model

      Construct a `tf.keras.Model` instance that requires only ``inputs``,
      which means you do not have to provide dummy target values when
      predicting at test points.

      Predict with

      .. code-block:: python

          model.predict(Xtest, ...)

      .. note:: The returned model will not support training; for that, use `as_training_model`.

      :param model_class: The model class to use; overrides `default_model_class`.



